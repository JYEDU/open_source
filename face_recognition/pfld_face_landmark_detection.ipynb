{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face landmark detection with PFLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "[1] [[Paper](https://arxiv.org/abs/1902.10859)] [[Github](https://github.com/polarisZhao/PFLD-pytorch)] Xiaojie Guo, Siyuan Li, Jinke Yu, Jiawan Zhang, Jiayi Ma, Lin Ma, Wei Liu, and Haibin Ling, \"PFLD: A practical facial landmark detector.\" arXiv, 2019\n",
    "\n",
    "[2] [[Paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Look_at_Boundary_CVPR_2018_paper.html)] [[Dataset](https://wywu.github.io/projects/LAB/WFLW.html)] Wayne Wu, Chen Qian, Shuo Yang, Quan Wang, Yici Cai, and Qiang Zhou, \"Look at Boundary: A Boundary-Aware Face Alignment Algorithm\", Proceedings of the IEEE conference on computer vision and pattern recognition, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "- Create virtual environment and install library\n",
    "    - conda create -n pfld_pytorch python=3.10\n",
    "    - conda activate pfld_pytorch\n",
    "    - pip install torch torchvision\n",
    "    - pip install opencv-python tensorboardX matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "- Download the PFLD git and WFLW dataset\n",
    "    - [PFLD github](https://github.com/polarisZhao/PFLD-pytorch)\n",
    "    - [WFLW dataset](https://wywu.github.io/projects/LAB/WFLW.html)\n",
    "\n",
    "- Unzip WFLW dataset and put them on ```./data/WFLW/```\n",
    "\n",
    "    ``` tar -zxvf WFLW_images.tar.gz ```\n",
    "\n",
    "    ``` tar -zxvf WFLW_annotations.tar.gz ```\n",
    "\n",
    "- Move Mirror98.txt to ```WFLW/WFLW_annotations```\n",
    "\n",
    "- Place the files as follows:\n",
    "\n",
    "    ```\n",
    "    PFLD-pytorch-master                      # from PFLD git\n",
    "    └── data                                 # Dataset\n",
    "        └── WFLW\n",
    "            └── WFLW_images\n",
    "            └── WFLW_annotations\n",
    "                └── Mirror98.txt\n",
    "    ```\n",
    "\n",
    "- Prepare train and test data\n",
    "    ```\n",
    "    python data/SetPreparation.py\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 삽입\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn.detector import detect_faces\n",
    "from collections import OrderedDict\n",
    "\n",
    "from models.pfld import PFLDInference, AuxiliaryNet\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "model_path =        # trained model 경로\n",
    "test_img_path =     # test image 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PFLD Inference 함수\n",
    "def landmark_detection(img, det, model_path):\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    pfld_backbone = PFLDInference().to(device)\n",
    "    pfld_backbone.load_state_dict(checkpoint['pfld_backbone'])\n",
    "    pfld_backbone.eval()\n",
    "    pfld_backbone = pfld_backbone.to(device)\n",
    "    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "     \n",
    "    height, width = img.shape[:2]\n",
    "    x1, y1, x2, y2 = (det[:4] + 0.5).astype(np.int32)\n",
    "\n",
    "    w = x2 - x1 + 1\n",
    "    h = y2 - y1 + 1\n",
    "    cx = x1 + w // 2\n",
    "    cy = y1 + h // 2\n",
    "\n",
    "    size = int(max([w, h]) * 1.1)\n",
    "    x1 = cx - size // 2\n",
    "    x2 = x1 + size\n",
    "    y1 = cy - size // 2\n",
    "    y2 = y1 + size\n",
    "\n",
    "    x1 = max(0, x1)\n",
    "    y1 = max(0, y1)\n",
    "    x2 = min(width, x2)\n",
    "    y2 = min(height, y2)\n",
    "\n",
    "    edx1 = max(0, -x1)\n",
    "    edy1 = max(0, -y1)\n",
    "    edx2 = max(0, x2 - width)\n",
    "    edy2 = max(0, y2 - height)\n",
    "\n",
    "    cropped = img[y1:y2, x1:x2]\n",
    "    if (edx1 > 0 or edy1 > 0 or edx2 > 0 or edy2 > 0):\n",
    "        cropped = cv2.copyMakeBorder(cropped, edy1, edy2, edx1, edx2,\n",
    "                                        cv2.BORDER_CONSTANT, 0)\n",
    "\n",
    "    input = cv2.resize(cropped, (112, 112))\n",
    "    input = transform(input).unsqueeze(0).to(device)\n",
    "    _, landmarks = pfld_backbone(input)\n",
    "    pre_landmark = landmarks[0]\n",
    "    pre_landmark = pre_landmark.cpu().detach().numpy().reshape(\n",
    "        -1, 2) * [size, size] - [edx1, edy1]\n",
    "    \n",
    "    result = []\n",
    "    for p in pre_landmark:\n",
    "        x = p[0] + x1 \n",
    "        y = p[1] + y1\n",
    "        result.append([int(x), int(y)])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Golden Ratio 계산 함수\n",
    "def calc_gr(pts, bounding_boxes, n =4):\n",
    "    result = []\n",
    "    A = pts[64][1] - pts[76][1]\n",
    "    B = pts[76][1] - pts[16][1]\n",
    "    \n",
    "    result.append(round(A/B,n))\n",
    "    \n",
    "    A = bounding_boxes[1] - pts[59][1]\n",
    "    B = pts[59][1] - pts[16][1]\n",
    "    \n",
    "    result.append(round(A/B,n))\n",
    "    \n",
    "    A = pts[64][0] - pts[0][0]\n",
    "    B = pts[68][0] - pts[64][0]\n",
    "    \n",
    "    result.append(round(A/B,n))\n",
    "    A = pts[32][0] - pts[68][0]\n",
    "    B = pts[68][0] - pts[64][0]\n",
    "    \n",
    "    result.append(round(A/B,n))\n",
    "    return result, sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 이미지 황금비 계산하기\n",
    "test_img = cv2.imread(test_img_path)\n",
    "test_img_gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "bounding_boxes, _ = detect_faces(test_img_gray) # bounding boxes : [x1. y1. x2. y2, confidence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark = landmark_detection(test_img, bounding_boxes[0][:4] , model_path)\n",
    "\n",
    "for p in landmark:\n",
    "    cv2.circle(test_img, (p[0], p[1]), 2, (255, 0, 0), -1)\n",
    "\n",
    "result_list, result = calc_gr(landmark,bounding_boxes[0][:4])\n",
    "cv2.putText(test_img, \"golden ratio : \" + str(round(result, 3)), (10,20),cv2.FONT_HERSHEY_DUPLEX, 0.5,(255,0,0), thickness=1, lineType=cv2.LINE_AA)\n",
    "cv2.imwrite(\"../result.png\", test_img)\n",
    "print(f\"황금비 결과 리스트 : {result_list}, 황금비 결과 평균값 : {result:.3f}\")\n",
    "\n",
    "plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfld_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
